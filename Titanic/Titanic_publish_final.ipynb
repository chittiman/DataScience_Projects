{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history. In this notebook we apply the tools of machine learning to predict which passengers survived the tragedy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chitr\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "#importing the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are loading the csv files and converting them into dataframes using read_csv function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"titanic_data.csv\")\n",
    "df_test  = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are splitting the data into training and validation sets. We fit the model using training data and check how well it can generalize to new data using validation dataset. (stratify = df_raw['Survived'].values) ensures the proportion of survived people is same in both training and validation datasets. This is to ensure that apriori probability for each label is same in both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn,df_val,label_trn,label_val = train_test_split(df_raw,df_raw[['PassengerId','Survived']],\n",
    "                                                stratify = df_raw['Survived'].values,test_size = 0.3,random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>Yrois, Miss. Henriette (\"Mrs Harbeck\")</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.000</td>\n",
       "      <td>0</td>\n",
       "      <td>248747</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>469</td>\n",
       "      <td>3</td>\n",
       "      <td>Scanlan, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.725</td>\n",
       "      <td>0</td>\n",
       "      <td>36209</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>199</td>\n",
       "      <td>3</td>\n",
       "      <td>Madigan, Miss. Margaret \"Maggie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.750</td>\n",
       "      <td>0</td>\n",
       "      <td>370370</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>575</td>\n",
       "      <td>3</td>\n",
       "      <td>Rush, Mr. Alfred George John</td>\n",
       "      <td>male</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.050</td>\n",
       "      <td>0</td>\n",
       "      <td>A/4. 20589</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>777</td>\n",
       "      <td>3</td>\n",
       "      <td>Tobin, Mr. Roger</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.750</td>\n",
       "      <td>0</td>\n",
       "      <td>383121</td>\n",
       "      <td>0</td>\n",
       "      <td>F38</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                    Name     Sex  \\\n",
       "199          200       2  Yrois, Miss. Henriette (\"Mrs Harbeck\")  female   \n",
       "468          469       3                      Scanlan, Mr. James    male   \n",
       "198          199       3        Madigan, Miss. Margaret \"Maggie\"  female   \n",
       "574          575       3            Rush, Mr. Alfred George John    male   \n",
       "776          777       3                        Tobin, Mr. Roger    male   \n",
       "\n",
       "      Age    Fare  Parch      Ticket  SibSp Cabin Embarked  Survived  \n",
       "199  24.0  13.000      0      248747      0   NaN        S         0  \n",
       "468   NaN   7.725      0       36209      0   NaN        Q         0  \n",
       "198   NaN   7.750      0      370370      0   NaN        Q         1  \n",
       "574  16.0   8.050      0  A/4. 20589      0   NaN        S         0  \n",
       "776   NaN   7.750      0      383121      0   F38        Q         0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are extracting the columns with null values in each dataframes and their counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age         122\n",
      "Cabin       493\n",
      "Embarked      1\n",
      "dtype: int64\n",
      "Age          55\n",
      "Cabin       194\n",
      "Embarked      1\n",
      "dtype: int64\n",
      "Age       86\n",
      "Fare       1\n",
      "Cabin    327\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for df in [df_trn,df_val,df_test]:\n",
    "    print(df.isnull().sum()[df.isnull().sum() != 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Embarked columns has very few null values and also Embarked column in test dataset doesnt have any null values we can drop those rows which have null value in Embarked column using dropna method on dataframes. Also the missing values in fare are replaced with the median value of Fare of training set. Filling missing values with median values makes better sense when the distribution have outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chitr\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\chitr\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for df in [df_trn,df_val,df_test]:\n",
    "    df.dropna(subset = ['Embarked'],inplace  = True)\n",
    "    df['Fare'] = df['Fare'].fillna(df_trn['Fare'].median())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are splitting the Name column and extracting the family name and Title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chitr\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\chitr\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "for df in [df_trn,df_val,df_test]: \n",
    "    df.loc[:,'Fmly_Name'] = df.Name.str.rsplit(pat=',',expand = True).iloc[:,0]\n",
    "    df.loc[:,'Title'] = df.Name.str.rsplit(pat=',',expand = True).iloc[:,1].\\\n",
    "    str.rsplit(pat = '.',expand  = True).iloc[:,0].str[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr              360\n",
      "Miss            122\n",
      "Mrs              92\n",
      "Master           29\n",
      "Dr                5\n",
      "Rev               4\n",
      "Ms                1\n",
      "Col               1\n",
      "Don               1\n",
      "Jonkheer          1\n",
      "the Countess      1\n",
      "Sir               1\n",
      "Lady              1\n",
      "Mme               1\n",
      "Major             1\n",
      "Mlle              1\n",
      "Name: Title, dtype: int64\n",
      "Mr        157\n",
      "Miss       59\n",
      "Mrs        32\n",
      "Master     11\n",
      "Rev         2\n",
      "Dr          2\n",
      "Major       1\n",
      "Capt        1\n",
      "Mlle        1\n",
      "Col         1\n",
      "Name: Title, dtype: int64\n",
      "Mr        240\n",
      "Miss       78\n",
      "Mrs        72\n",
      "Master     21\n",
      "Col         2\n",
      "Rev         2\n",
      "Ms          1\n",
      "Dr          1\n",
      "Dona        1\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for df in [df_trn,df_val,df_test]: \n",
    "    print(df.Title.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After observing the counts of different values, we are replacing the values which apppear rarely with appropriate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chitr\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3798: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  method=method)\n"
     ]
    }
   ],
   "source": [
    "for df in [df_trn,df_val,df_test]:\n",
    "    df.replace(to_replace = ['Rev','Major','Jonkheer','Dr','Sir','Don', 'Col','Capt'],value =  'Mr',inplace = True)\n",
    "    df.replace(to_replace =['Ms',    'Lady', 'Mlle','Dona'],value = 'Miss',inplace = True)\n",
    "    df.replace(to_replace =['Mme', 'the Countess'],value = 'Mrs',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Miss' 'Mr' 'Mrs' 'Master']\n",
      "['Mr' 'Mrs' 'Master' 'Miss']\n",
      "['Mr' 'Mrs' 'Miss' 'Master']\n"
     ]
    }
   ],
   "source": [
    "for df in [df_trn,df_val,df_test]: \n",
    "    print(df.Title.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age columns has large number of missing values. Here we are grouping the age column based on the title and for each group we are finding the mean value of each group and we are using these values to fill the missing values in the age column appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_median(series):\n",
    "    return series.fillna(series.median())\n",
    "for df in [df_trn,df_val,df_test]:\n",
    "    df.Age = df.groupby('Title')['Age'].transform(impute_median)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are creating new feature called Family which is the sum of the siblings, spouse, parents and the children. Eventhough survival rate depends on the sex, but its effect is more predominant in first class and comparatively less in the third class.\n",
    "This might be because of interaction effect between sex and class and hence we are creating a new feature sec_class inorder to capture this interaction. Also we are standardizing the Age feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Age_mean = df_raw['Age'].mean()\n",
    "Age_std = df_raw['Age'].std()\n",
    "\n",
    "for df in [df_trn,df_val,df_test]: \n",
    "    df['Family'] = df['Parch'] + df['SibSp']\n",
    "    df['Sex'] = df.Sex.map({'male':0,'female':1})\n",
    "    df['Sex_class'] = df['Pclass']*df['Sex']\n",
    "    df['Embarked_map'] = df['Embarked'].map({'S':1,'Q':2,'C':3})\n",
    "    df['Title_map'] = df['Title'].map({'Mr':1,'Miss':2,'Mrs':3,'Master':4})\n",
    "    df['Pclass_map'] = df['Pclass']\n",
    "    df['Age_std'] = (df['Age'] - Age_mean)/Age_std\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the classifiers work only with numerical values. Unordered categorical variables like Embarked and Title are passed onto get_dummies function to create a signal feature for each value in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.get_dummies(df_trn, columns=['Embarked','Title','Pclass'])\n",
    "df_val = pd.get_dummies(df_val, columns=['Embarked','Title','Pclass'])\n",
    "df_test = pd.get_dummies(df_test, columns=['Embarked','Title','Pclass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here to the Random forest classifier we are sending a different combination of features. and observe how accuracy is varying \n",
    "for both training and validation datasets and after that select best features.\n",
    "\n",
    "But this is process is done separately for two groups, for those who are travelling alone and those who are travelling with families."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sex']\n",
      "Train_score = 0.8306878306878307 , Crossvalidation_score = 0.8280254777070064\n",
      "['Sex', 'Pclass_1']\n",
      "Train_score = 0.8306878306878307 , Crossvalidation_score = 0.8280254777070064\n",
      "['Sex', 'Pclass_1', 'Embarked_C']\n",
      "Train_score = 0.8306878306878307 , Crossvalidation_score = 0.8280254777070064\n",
      "['Sex', 'Pclass_1', 'Embarked_C', 'Age_std']\n",
      "Train_score = 0.8862433862433863 , Crossvalidation_score = 0.8152866242038217\n",
      "['Sex', 'Pclass_1', 'Embarked_C', 'Age_std', 'Pclass_2']\n",
      "Train_score = 0.9047619047619048 , Crossvalidation_score = 0.8089171974522293\n",
      "['Sex', 'Pclass_1', 'Embarked_C', 'Age_std', 'Pclass_2', 'Title_Master']\n",
      "Train_score = 0.9047619047619048 , Crossvalidation_score = 0.8089171974522293\n",
      "['Sex', 'Pclass_1', 'Embarked_C', 'Age_std', 'Pclass_2', 'Title_Master', 'Pclass_3']\n",
      "Train_score = 0.9047619047619048 , Crossvalidation_score = 0.8089171974522293\n",
      "['Sex', 'Pclass_1', 'Embarked_C', 'Age_std', 'Pclass_2', 'Title_Master', 'Pclass_3', 'Title_Mrs']\n",
      "Train_score = 0.9074074074074074 , Crossvalidation_score = 0.7961783439490446\n",
      "['Sex', 'Pclass_1', 'Embarked_C', 'Age_std', 'Pclass_2', 'Title_Master', 'Pclass_3', 'Title_Mrs', 'Embarked_Q']\n",
      "Train_score = 0.9074074074074074 , Crossvalidation_score = 0.7961783439490446\n",
      "['Sex', 'Pclass_1', 'Embarked_C', 'Age_std', 'Pclass_2', 'Title_Master', 'Pclass_3', 'Title_Mrs', 'Embarked_Q', 'SibSp']\n",
      "Train_score = 0.9074074074074074 , Crossvalidation_score = 0.8152866242038217\n",
      "['Sex', 'Pclass_1', 'Embarked_C', 'Age_std', 'Pclass_2', 'Title_Master', 'Pclass_3', 'Title_Mrs', 'Embarked_Q', 'SibSp', 'Parch']\n",
      "Train_score = 0.9074074074074074 , Crossvalidation_score = 0.7834394904458599\n",
      "['Sex', 'Pclass_1', 'Embarked_C', 'Age_std', 'Pclass_2', 'Title_Master', 'Pclass_3', 'Title_Mrs', 'Embarked_Q', 'SibSp', 'Parch', 'Family']\n",
      "Train_score = 0.9074074074074074 , Crossvalidation_score = 0.8152866242038217\n",
      "['Sex', 'Pclass_1', 'Embarked_C', 'Age_std', 'Pclass_2', 'Title_Master', 'Pclass_3', 'Title_Mrs', 'Embarked_Q', 'SibSp', 'Parch', 'Family', 'Title_Miss']\n",
      "Train_score = 0.9074074074074074 , Crossvalidation_score = 0.8152866242038217\n",
      "['Sex', 'Pclass_1', 'Embarked_C', 'Age_std', 'Pclass_2', 'Title_Master', 'Pclass_3', 'Title_Mrs', 'Embarked_Q', 'SibSp', 'Parch', 'Family', 'Title_Miss', 'Title_Mr']\n",
      "Train_score = 0.9074074074074074 , Crossvalidation_score = 0.802547770700637\n",
      "['Sex', 'Pclass_1', 'Embarked_C', 'Age_std', 'Pclass_2', 'Title_Master', 'Pclass_3', 'Title_Mrs', 'Embarked_Q', 'SibSp', 'Parch', 'Family', 'Title_Miss', 'Title_Mr', 'Embarked_S']\n",
      "Train_score = 0.9074074074074074 , Crossvalidation_score = 0.7961783439490446\n",
      "['Sex', 'Pclass_1', 'Embarked_C', 'Age_std', 'Pclass_2', 'Title_Master', 'Pclass_3', 'Title_Mrs', 'Embarked_Q', 'SibSp', 'Parch', 'Family', 'Title_Miss', 'Title_Mr', 'Embarked_S', 'Sex_class']\n",
      "Train_score = 0.9074074074074074 , Crossvalidation_score = 0.7961783439490446\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100,max_features=0.8)\n",
    "features_all = ['Sex','Pclass_1','Embarked_C','Age_std','Pclass_2','Title_Master','Pclass_3','Title_Mrs','Embarked_Q','SibSp','Parch','Family',\n",
    "'Title_Miss','Title_Mr','Embarked_S','Sex_class']\n",
    "for i in range(len(features_all)):\n",
    "    features = features_all[:i+1]\n",
    "    clf.fit(df_trn[df_trn['Family'] == 0][features],df_trn[df_trn['Family'] == 0]['Survived'])\n",
    "    pred_train = clf.predict(df_trn[df_trn['Family'] == 0][features])\n",
    "    pred_val = clf.predict(df_val[df_val['Family'] == 0][features])\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print(features)\n",
    "    print(\"Train_score = \" + str(accuracy_score(pred_train,df_trn[df_trn['Family'] == 0]['Survived'])) + ' , '\\\n",
    "          +\"Crossvalidation_score = \" + str(accuracy_score(pred_val,df_val[df_val['Family'] == 0]['Survived'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_single_features = ['Sex','Pclass_1','Embarked_C','Age']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age']\n",
      "Train_score = 0.7377049180327869 , Crossvalidation_score = 0.5454545454545454\n",
      "['Age', 'Sex']\n",
      "Train_score = 0.8565573770491803 , Crossvalidation_score = 0.6545454545454545\n",
      "['Age', 'Sex', 'Fare']\n",
      "Train_score = 1.0 , Crossvalidation_score = 0.6909090909090909\n",
      "['Age', 'Sex', 'Fare', 'Pclass_map']\n",
      "Train_score = 1.0 , Crossvalidation_score = 0.7909090909090909\n",
      "['Age', 'Sex', 'Fare', 'Pclass_map', 'Title_map']\n",
      "Train_score = 1.0 , Crossvalidation_score = 0.8272727272727273\n",
      "['Age', 'Sex', 'Fare', 'Pclass_map', 'Title_map', 'Embarked_map']\n",
      "Train_score = 1.0 , Crossvalidation_score = 0.8363636363636363\n"
     ]
    }
   ],
   "source": [
    "features_all = ['Age','Sex','Fare','Pclass_map','Title_map','Embarked_map']\n",
    "#features_all = ['Sex','Age','Pclass_1','Pclass_2','Pclass_3','SibSp','Parch','Family', \n",
    "#'Title_Master','Title_Miss','Title_Mr','Title_Mrs','Embarked_C','Embarked_Q','Embarked_S']\n",
    "for i in range(len(features_all)):\n",
    "    features = features_all[:i+1]\n",
    "    clf.fit(df_trn[df_trn['Family'] > 0][features],df_trn[df_trn['Family'] > 0]['Survived'])\n",
    "    pred_train = clf.predict(df_trn[df_trn['Family'] > 0][features])\n",
    "    pred_val = clf.predict(df_val[df_val['Family'] > 0][features])\n",
    "\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print(features)\n",
    "    print(\"Train_score = \" + str(accuracy_score(pred_train,df_trn[df_trn['Family'] > 0]['Survived'])) + ' , '\\\n",
    "          +\"Crossvalidation_score = \" + str(accuracy_score(pred_val,df_val[df_val['Family'] > 0]['Survived'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_group_features = ['Age','Sex','Fare','Pclass_map','Title_map','Embarked_map']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are slecting the best features and predict the outcomes for those with and without families separately and then combined both the datafranes using concat function and finally convert the dataframe into a csv file using to_csv method on the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chitr\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\chitr\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "df_alone = df_test[df_test['Family'] == 0]\n",
    "df_grp = df_test[df_test['Family'] != 0]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100,max_features=0.8)\n",
    "clf.fit(df_trn[df_trn['Family'] == 0][best_single_features],df_trn[df_trn['Family'] == 0]['Survived'])\n",
    "df_alone['Survived'] = clf.predict(df_alone[best_single_features])\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100,max_features=0.8)\n",
    "clf.fit(df_trn[df_trn['Family'] > 0][best_group_features],df_trn[df_trn['Family'] > 0]['Survived'])\n",
    "df_grp['Survived'] = clf.predict(df_grp[best_group_features])\n",
    "\n",
    "df_test = pd.concat([df_alone,df_grp]).sort_index()\n",
    "#df_test[['PassengerId','Survived']].to_csv('Separate_best_Predn.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
